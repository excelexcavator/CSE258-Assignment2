{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from random import choice\n",
    "import gzip\n",
    "import scipy\n",
    "import sys\n",
    "\n",
    "class ShowProcess():\n",
    "    i = 0\n",
    "    max_steps = 0\n",
    "    max_arrow = 50 # length of bar\n",
    "    infoDone = 'done'\n",
    "    \n",
    "    def __init__(self, max_steps, infoDone = 'Done'):\n",
    "        self.max_steps = max_steps\n",
    "        self.i = 0\n",
    "        self.infoDone = infoDone\n",
    "    \n",
    "    def show_process(self, i=None):\n",
    "        if i is not None:\n",
    "            self.i = i\n",
    "        else:\n",
    "            self.i += 1\n",
    "        num_arrow = int(self.i * self.max_arrow / self.max_steps)\n",
    "        num_line = self.max_arrow - num_arrow\n",
    "        percent = self.i * 100.0 / self.max_steps\n",
    "        process_bar = '[' + '>' * num_arrow + '-' * num_line + ']'\\\n",
    "            + '%.2f' % percent + '%' + '\\r'\n",
    "        sys.stdout.write(process_bar)\n",
    "        sys.stdout.flush()\n",
    "        if self.i >= self.max_steps:\n",
    "            self.close()\n",
    "\n",
    "    def close(self):\n",
    "        print('')\n",
    "        print(self.infoDone)\n",
    "        self.i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('beer_train.csv')\n",
    "data_val = pd.read_csv('beer_val.csv')\n",
    "data_test = pd.read_csv('beer_test.csv')\n",
    "data_train = np.array(data_train[['user_id','beer_id','review_overall']]).astype(str)\n",
    "data_val = np.array(data_val[['user_id','beer_id','review_overall']]).astype(str)\n",
    "data_test = np.array(data_test[['user_id','beer_id','review_overall']]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      " \n"
     ]
    }
   ],
   "source": [
    "users = list(set(data_train[:,0]))\n",
    "items = list(set(data_train[:,1]))\n",
    "nUsers = len(users)\n",
    "nItems = len(items)\n",
    "\n",
    "getBeerByUser = defaultdict(str)\n",
    "getUserByBeer = defaultdict(str)\n",
    "\n",
    "process_bar = ShowProcess(len(data_train), ' ')\n",
    "for i in range(len(data_train)):\n",
    "    process_bar.show_process()\n",
    "    u, b, _ = data_train[i]\n",
    "    if u not in getBeerByUser:\n",
    "        getBeerByUser[u] = data_train[data_train[:,0]==u,1]\n",
    "    if b not in getUserByBeer:\n",
    "        getUserByBeer[b] = data_train[data_train[:,1]==b,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(set(data_train[:,0]))\n",
    "items = list(set(data_train[:,1]))\n",
    "nUsers = len(users)\n",
    "nItems = len(items)\n",
    "alpha = np.average(data_train[:,2].astype(float))\n",
    "\n",
    "F = 5 # dimension of vector gammaUser and gammaItem\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "gammaUser = dict()\n",
    "gammaItem = dict()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "\n",
    "def RMSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return np.sqrt(sum(differences) / len(differences))\n",
    "\n",
    "def prediction(user, item):\n",
    "    if user not in userBiases:\n",
    "        uB = 0\n",
    "        uG = np.zeros(F)\n",
    "    else:\n",
    "        uB = userBiases[user]\n",
    "        uG = gammaUser[user]\n",
    "    if item not in itemBiases:\n",
    "        iB = 0\n",
    "        iG = np.zeros(F)\n",
    "    else:\n",
    "        iB = itemBiases[item]\n",
    "        iG = gammaItem[item]\n",
    "    result = alpha + uB + iB\n",
    "    result += np.matmul(uG, iG)\n",
    "    return result\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    global gammaUser\n",
    "    global gammaItem\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[nUsers+1:nUsers+nItems+1]))\n",
    "    for i in range(nUsers):\n",
    "        gammaUser[users[i]] = np.array(theta[nUsers+nItems+1+F*i:nUsers+nItems+1+F*(i+1)])\n",
    "    for i in range(nItems):\n",
    "        gammaItem[items[i]] = np.array(theta[nUsers+nItems+1+F*(nUsers+i):nUsers+nItems+1+F*(nUsers+i+1)])\n",
    "    \n",
    "def cost(theta, labels, lamb):\n",
    "    global loss_train\n",
    "    global loss_val\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in data_train]\n",
    "    cost = RMSE(predictions, labels)\n",
    "    \n",
    "    pred_val = [prediction(u,b) for u,b,_ in data_val]\n",
    "    cost_val = RMSE(pred_val, data_val[:,2].astype(float))\n",
    "    print(\"train RMSE = {:1.3f}\".format(cost) + \"     val RMSE = {:1.3f}\".format(cost_val))\n",
    "    loss_train.append(cost)\n",
    "    loss_val.append(cost_val)\n",
    "    \n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "        cost += lamb*sum(gammaUser[u]**2)\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "        cost += lamb*sum(gammaItem[i]**2)\n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(data_train)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    dgammaUser = dict()\n",
    "    dgammaItem = dict()\n",
    "    for d in data_train:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d[2].astype(float)\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "        dgammaUser[u] = 2/N*gammaItem[i]*diff\n",
    "        dgammaItem[i] = 2/N*gammaUser[u]*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "        dgammaUser[u] += 2*lamb*gammaUser[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "        dgammaItem[i] += 2*lamb*gammaItem[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    for u in users: dtheta += list(dgammaUser[u])\n",
    "    for i in items: dtheta += list(dgammaItem[i])\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE = 2.450     val RMSE = 2.344\n",
      "train RMSE = 1.581     val RMSE = 1.526\n",
      "train RMSE = 0.967     val RMSE = 1.088\n",
      "train RMSE = 0.967     val RMSE = 1.087\n",
      "train RMSE = 0.966     val RMSE = 1.087\n",
      "train RMSE = 0.961     val RMSE = 1.084\n",
      "train RMSE = 0.945     val RMSE = 1.073\n",
      "train RMSE = 0.894     val RMSE = 1.045\n",
      "train RMSE = 0.908     val RMSE = 1.054\n",
      "train RMSE = 0.862     val RMSE = 1.006\n",
      "train RMSE = 0.986     val RMSE = 1.069\n",
      "train RMSE = 0.970     val RMSE = 1.047\n",
      "train RMSE = 0.888     val RMSE = 0.942\n",
      "train RMSE = 0.858     val RMSE = 0.903\n",
      "train RMSE = 0.888     val RMSE = 0.924\n",
      "train RMSE = 0.961     val RMSE = 0.995\n",
      "train RMSE = 1.061     val RMSE = 1.093\n",
      "train RMSE = 1.103     val RMSE = 1.134\n",
      "train RMSE = 1.149     val RMSE = 1.178\n",
      "train RMSE = 1.149     val RMSE = 1.176\n",
      "train RMSE = 1.087     val RMSE = 1.115\n",
      "train RMSE = 1.746     val RMSE = 1.750\n",
      "train RMSE = 1.172     val RMSE = 1.190\n",
      "train RMSE = 1.097     val RMSE = 1.121\n",
      "train RMSE = 0.996     val RMSE = 1.023\n",
      "train RMSE = 7.186     val RMSE = 7.081\n",
      "train RMSE = 2.380     val RMSE = 2.363\n",
      "train RMSE = 1.209     val RMSE = 1.223\n",
      "train RMSE = 1.035     val RMSE = 1.058\n",
      "train RMSE = 1.002     val RMSE = 1.029\n",
      "train RMSE = 0.937     val RMSE = 0.965\n",
      "train RMSE = 0.869     val RMSE = 0.900\n",
      "train RMSE = 0.918     val RMSE = 0.947\n",
      "train RMSE = 0.811     val RMSE = 0.845\n",
      "train RMSE = 0.756     val RMSE = 0.794\n",
      "train RMSE = 0.772     val RMSE = 0.808\n",
      "train RMSE = 0.786     val RMSE = 0.822\n",
      "train RMSE = 0.752     val RMSE = 0.792\n",
      "train RMSE = 0.704     val RMSE = 0.746\n",
      "train RMSE = 0.708     val RMSE = 0.748\n",
      "train RMSE = 0.693     val RMSE = 0.734\n",
      "train RMSE = 0.686     val RMSE = 0.727\n",
      "train RMSE = 0.682     val RMSE = 0.724\n",
      "train RMSE = 0.678     val RMSE = 0.719\n",
      "train RMSE = 0.666     val RMSE = 0.708\n",
      "train RMSE = 0.833     val RMSE = 0.861\n",
      "train RMSE = 0.658     val RMSE = 0.699\n",
      "train RMSE = 0.955     val RMSE = 0.972\n",
      "train RMSE = 0.649     val RMSE = 0.689\n",
      "train RMSE = 0.627     val RMSE = 0.670\n",
      "train RMSE = 0.622     val RMSE = 0.665\n",
      "train RMSE = 0.621     val RMSE = 0.665\n",
      "train RMSE = 0.621     val RMSE = 0.665\n",
      "train RMSE = 0.660     val RMSE = 0.700\n",
      "train RMSE = 0.622     val RMSE = 0.666\n",
      "train RMSE = 0.621     val RMSE = 0.664\n",
      "train RMSE = 0.620     val RMSE = 0.663\n",
      "train RMSE = 0.619     val RMSE = 0.662\n",
      "train RMSE = 0.618     val RMSE = 0.660\n",
      "train RMSE = 0.616     val RMSE = 0.657\n",
      "train RMSE = 0.609     val RMSE = 0.651\n",
      "train RMSE = 0.606     val RMSE = 0.648\n",
      "train RMSE = 0.606     val RMSE = 0.648\n",
      "train RMSE = 0.609     val RMSE = 0.651\n",
      "train RMSE = 0.607     val RMSE = 0.649\n",
      "train RMSE = 0.606     val RMSE = 0.648\n",
      "train RMSE = 0.607     val RMSE = 0.648\n",
      "train RMSE = 0.607     val RMSE = 0.648\n",
      "train RMSE = 0.608     val RMSE = 0.649\n",
      "train RMSE = 0.607     val RMSE = 0.648\n",
      "train RMSE = 0.610     val RMSE = 0.650\n",
      "train RMSE = 0.605     val RMSE = 0.646\n",
      "train RMSE = 0.602     val RMSE = 0.644\n",
      "train RMSE = 0.602     val RMSE = 0.644\n",
      "train RMSE = 0.598     val RMSE = 0.641\n",
      "train RMSE = 0.597     val RMSE = 0.639\n",
      "train RMSE = 0.597     val RMSE = 0.639\n",
      "train RMSE = 0.596     val RMSE = 0.639\n",
      "train RMSE = 0.596     val RMSE = 0.638\n",
      "train RMSE = 0.596     val RMSE = 0.638\n",
      "train RMSE = 0.597     val RMSE = 0.638\n",
      "train RMSE = 0.597     val RMSE = 0.638\n",
      "train RMSE = 0.595     val RMSE = 0.637\n",
      "train RMSE = 0.595     val RMSE = 0.636\n",
      "train RMSE = 0.594     val RMSE = 0.636\n",
      "train RMSE = 0.594     val RMSE = 0.636\n",
      "train RMSE = 0.594     val RMSE = 0.636\n",
      "train RMSE = 0.637     val RMSE = 0.674\n",
      "train RMSE = 0.594     val RMSE = 0.636\n",
      "train RMSE = 0.594     val RMSE = 0.635\n",
      "train RMSE = 0.594     val RMSE = 0.635\n",
      "train RMSE = 0.594     val RMSE = 0.635\n",
      "train RMSE = 0.593     val RMSE = 0.635\n",
      "train RMSE = 0.843     val RMSE = 0.864\n",
      "train RMSE = 0.595     val RMSE = 0.636\n",
      "train RMSE = 0.593     val RMSE = 0.635\n",
      "train RMSE = 0.593     val RMSE = 0.634\n",
      "train RMSE = 0.842     val RMSE = 0.865\n",
      "train RMSE = 0.596     val RMSE = 0.636\n",
      "train RMSE = 0.593     val RMSE = 0.634\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.593     val RMSE = 0.634\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 1.223     val RMSE = 1.226\n",
      "train RMSE = 0.600     val RMSE = 0.639\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.591     val RMSE = 0.632\n",
      "train RMSE = 0.591     val RMSE = 0.632\n",
      "train RMSE = 0.591     val RMSE = 0.632\n",
      "train RMSE = 0.594     val RMSE = 0.634\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.591     val RMSE = 0.632\n",
      "train RMSE = 0.591     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.591     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.602     val RMSE = 0.642\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.633\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.594     val RMSE = 0.633\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.620     val RMSE = 0.657\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.594     val RMSE = 0.633\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.633\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.593     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n",
      "train RMSE = 0.592     val RMSE = 0.632\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-5f50ef4b4253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnUsers\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnItems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-885cbf23a073>\u001b[0m in \u001b[0;36mderivative\u001b[0;34m(theta, labels, lamb)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mdUserBiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mdItemBiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mdgammaUser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgammaItem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mdgammaItem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgammaUser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muserBiases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = [alpha] + [np.random.rand() for i in range((nUsers+nItems)*(F+1))]\n",
    "x, f, d = scipy.optimize.fmin_l_bfgs_b(cost, init, derivative, args = (data_train[:,2].astype(float), 5e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE = 0.628\n"
     ]
    }
   ],
   "source": [
    "pred_test = [prediction(u,b) for u,b,_ in data_test]\n",
    "cost_test = RMSE(pred_test, data_test[:,2].astype(float))\n",
    "print(\"test RMSE = {:1.3f}\".format(cost_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\", context=\"talk\", font_scale=0.8)\n",
    "plt.plot(loss_train[:200])\n",
    "plt.plot(loss_val[:200])\n",
    "plt.legend(['training loss','validation loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31500"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "63*500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
